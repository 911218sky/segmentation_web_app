from typing import Optional, List
from pathlib import Path
import streamlit as st
import re
from PIL import Image

from utils.file import clean_folder
from config import TEMP_DIR, SA_FILE, IMAGE_COMPRESSOR
from utils.drive_fetcher import DriveFetcher, DriveFetchResult

# Google Drive URL matcher
_DRIVE_FILE_RE = re.compile(r'https?://(drive|docs)\.google\.com/.+')

# ä¸‹è¼‰ç·©å­˜è³‡æ–™å¤¾
UPDATE_DIR = Path(TEMP_DIR) / "uploaded_images"
UPDATE_DIR.mkdir(parents=True, exist_ok=True)

# åˆå§‹åŒ– DriveFetcher
fetcher = DriveFetcher(
    service_account_file=SA_FILE,
    allowed_extensions=['.jpg', '.jpeg', '.png'],
    max_workers=8,
)

def _is_drive_link(url: str) -> bool:
    """
    æª¢æŸ¥æ˜¯å¦ç‚º Google Drive åˆ†äº«é€£çµ
    """
    return bool(url and _DRIVE_FILE_RE.match(url.strip()))

def _set_cache(link: str, result: List[DriveFetchResult]):
    """
    è¨­å®šå¿«å–
    """
    if 'drive_img_link_cache' not in st.session_state:
        st.session_state['drive_img_link_cache'] = {}
    st.session_state['drive_img_link_cache'][link] = result

def _get_cache(link: str) -> Optional[List[DriveFetchResult]]:
    """
    å–å¾—å¿«å–
    """
    if 'drive_img_link_cache' not in st.session_state:
        return None
    return st.session_state['drive_img_link_cache'].get(link)

def _get_compressed_path(path: Path, ext: str) -> Path:
    """
    å–å¾—å£“ç¸®å¾Œçš„åœ–ç‰‡è·¯å¾‘
    """
    return path.with_name(f"{path.stem}_c{ext}")

def _compress_with_pillow(
    in_path: Path,
    out_path: Path,
    quality: int = 85,
    to_webp: bool = False,
):
    im = Image.open(in_path)
    if to_webp:
        im.save(out_path, "WEBP", quality=quality, method=6) 
    else:
        im = im.convert("RGB")
        im.save(out_path, "JPEG", quality=quality, optimize=True, progressive=True)

def google_img_update() -> Optional[List[Path]]:
    clean_folder(UPDATE_DIR, max_items=500, max_age_days=5)

    st.subheader("ğŸï¸ å¾ Google Drive åˆ†äº«é€£çµä¸‹è¼‰åœ–ç‰‡")
    hint = "è²¼ä¸Š Google Drive åˆ†äº«é€£çµ æˆ– ç›´æ¥è²¼ FILE_ID ç¯„ä¾‹ https://drive.google.com/drive/folders/1ppSMdn1YYdc8rN56uKgWJhqezzneajAY?usp=drive_link"
    
    url_input = st.text_area(
        "Drive åˆ†äº«é€£çµ æˆ– file id",
        placeholder=hint,
        key="drive_img_url_input",
        height=100,
    )

    download_btn = st.button("ç²å–åœ–ç‰‡", key="download_img_btn")
    st.info("è«‹è¼¸å…¥ Google Drive åˆ†äº«é€£çµæˆ– file idï¼Œç„¶å¾ŒæŒ‰ ç²å–åœ–ç‰‡")

    link = url_input.strip()
    if link and not _is_drive_link(link):
        st.error("è«‹è¼¸å…¥æœ‰æ•ˆçš„ Google Drive åˆ†äº«é€£çµæˆ– file idã€‚")
        return None

    # æª¢æŸ¥é€£çµç·©å­˜
    if _get_cache(link):
        result = _get_cache(link)
        if result:
            st.success(f"å·²ä½¿ç”¨é€£çµç·©å­˜ å…± {len(result)} å¼µåœ–ç‰‡")
            return [Path(r.path) for r in result]

    if not download_btn:
        return None

    # ä¸‹è¼‰åœ–ç‰‡
    try:
        with st.spinner("ç²å–è³‡æ–™ä¸­..."):
            all_exists = True
            results = fetcher.fetch(link, download_dir=UPDATE_DIR, recurse=False, only_list=True, preserve_structure=False)
            # å‡å¦‚æœ‰ç²å–çµæœæª¢æŸ¥æ˜¯å¦æœ‰å¿«å–
            if results and IMAGE_COMPRESSOR:
                # å£“ç¸®åœ–ç‰‡
                for r in results:
                    com_path = _get_compressed_path(r.path, r.path.suffix)
                    if com_path.exists():
                        r.path = com_path
                    else:
                        all_exists = False
                        break
            # å¦‚æœæ‰€æœ‰åœ–ç‰‡éƒ½å­˜åœ¨ï¼Œå‰‡å„²å­˜è‡³é€£çµç·©å­˜
            if all_exists:
                _set_cache(link, results)
                return [Path(r.path) for r in results]
            
            results = fetcher.fetch(link, download_dir=UPDATE_DIR, recurse=False, preserve_structure=False)
    except Exception as e:
        st.error(f"ä¸‹è¼‰éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return None
    
    st.success(f"ä¸‹è¼‰å®Œæˆ å…± {len(results)} å¼µåœ–ç‰‡")
    
    # å£“ç¸®åœ–ç‰‡
    if IMAGE_COMPRESSOR:
        with st.spinner("å£“ç¸®åœ–ç‰‡ä¸­..."):
            for r in results:
                com_path = _get_compressed_path(r.path, r.path.suffix)
                _compress_with_pillow(r.path, com_path, quality=85, to_webp=False)
                # åˆªé™¤åŸå§‹åœ–ç‰‡
                r.path.unlink()
                # æ›´æ–°çµæœè·¯å¾‘
                r.path = com_path
            st.success(f"å£“ç¸®å®Œæˆ å…± {len(results)} å¼µåœ–ç‰‡")

    # å„²å­˜è‡³é€£çµç·©å­˜
    _set_cache(link, results)
    return [Path(r.path) for r in results]